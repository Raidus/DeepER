{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepER Classic VS VinSIM + DeepER (Fine Tuning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Caricamento dati, preprocessing e strutture ausiliarie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from DeepER import init_embeddings_index, init_embeddings_model, init_DeepER_model, train_model_ER, replace_last_layer, model_statistics\n",
    "from experimental_similarity import mono_vector, mono_vector_fast, cosine_similarity_vector, distance_similarity_vector\n",
    "from csv2dataset import splitting_dataSet, csv_2_datasetALTERNATE, csvTable2datasetRANDOM\n",
    "from generate_similarity_vector import generate_similarity_vector\n",
    "from keras.models import load_model\n",
    "from keras.layers import Dense\n",
    "from plotly import graph_objs as go\n",
    "import plotly.offline as pyo\n",
    "from random import shuffle\n",
    "import utilist as uls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imposta manualmente a True per caricare da disco tutti i modelli salvati. \n",
    "# Imposta manualmente a False per ri-eseguire tutti gli addestramenti.\n",
    "LOAD_FROM_DISK = False\n",
    "# Il nome con cui saranno etichettati i files prodotti\n",
    "DATASET_NAME = # Esempio: 'WA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Caricamento strutture dati e modelli ausiliari.\n",
    "embeddings_index = init_embeddings_index('glove.6B.50d.txt')\n",
    "emb_dim = len(embeddings_index['cat']) # :3\n",
    "embeddings_model, tokenizer = init_embeddings_model(embeddings_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Caricamento dati e split iniziale.\n",
    "if LOAD_FROM_DISK:\n",
    "    \n",
    "    # Carica dataset salvato su disco.\n",
    "    data = uls.load_list(f'dataset_{DATASET_NAME}')\n",
    "\n",
    "else:\n",
    "    \n",
    "    GROUND_TRUTH_FILE = # Esempio: 'matches_walmart_amazon.csv'\n",
    "    # Necessario inserire le tabelle nell'ordine corrispondente alle coppie della ground truth.\n",
    "    TABLE1_FILE = # Esempio: 'walmart.csv'\n",
    "    TABLE2_FILE = # Esempio: 'amazon.csv'\n",
    "\n",
    "    # Coppie di attributi considerati allineati.\n",
    "    att_indexes =  [(1, 1), (2, 2), (3, 3), (4, 4)] # Esempio: [(5, 9), (4, 5), (3, 3), (14, 4), (6, 11)]\n",
    "\n",
    "    # Similarity callbacks\n",
    "    simf = lambda a, b: cosine_similarity_vector(a, b, embeddings_index)\n",
    "    #simf = lambda a, b: mono_vector_fast(a, b)\n",
    "    #simf = lambda a, b: mono_vector(a, b)\n",
    "\n",
    "    # Crea il dataset.\n",
    "    data = csv_2_datasetALTERNATE(GROUND_TRUTH_FILE, TABLE1_FILE, TABLE2_FILE, att_indexes, simf)\n",
    "    \n",
    "    # Salva dataset su disco.\n",
    "    uls.save_list(data, f'dataset_{DATASET_NAME}')\n",
    "\n",
    "    \n",
    "# Dataset per DeepER classico: [(tupla1, tupla2, label), ...].\n",
    "deeper_data = list(map(lambda q: (q[0], q[1], q[3]), data))\n",
    "\n",
    "\n",
    "# Taglia attributi se troppo lunghi\n",
    "# Alcuni dataset hanno attributi con descrizioni molto lunghe.\n",
    "# Questo filtro limita il numero di caratteri di un attributo a 1000.\n",
    "def shrink_data(data):\n",
    "    \n",
    "    def cut_string(s):\n",
    "        if len(s) >= 700:\n",
    "            return s[:700]\n",
    "        else:\n",
    "            return s\n",
    "    \n",
    "    temp = []\n",
    "    for t1, t2, lb in data:\n",
    "        t1 = list(map(cut_string, t1))\n",
    "        t2 = list(map(cut_string, t2))\n",
    "        temp.append((t1, t2, lb))\n",
    "        \n",
    "    return temp\n",
    "\n",
    "deeper_data = shrink_data(deeper_data)\n",
    "\n",
    "\n",
    "# Split in training set e test set.\n",
    "def split_training_test(data, SPLIT_FACTOR = 0.8):     \n",
    "    bound = int(len(data) * SPLIT_FACTOR)\n",
    "    train = data[:bound]\n",
    "    test = data[bound:]\n",
    "    \n",
    "    return train, test\n",
    "\n",
    "\n",
    "# Tutti i successivi addestramenti partiranno dal 100% di deeper_train (80% di tutti i dati).\n",
    "# Le tuple in deeper_test non verranno mai usate per addestrare ma solo per testare i modelli.\n",
    "deeper_train, deeper_test = split_training_test(deeper_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Addestramento standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# InPut: Percentuale di dati considerata per l'addestramento. \n",
    "# OutPut: DeepER addestrato sul taglio scelto.\n",
    "def get_DeepER(perc):\n",
    "   \n",
    "    sub_data = splitting_dataSet(perc, deeper_train)    \n",
    "    \n",
    "    if LOAD_FROM_DISK:\n",
    "        \n",
    "        # Carica da disco.\n",
    "        print(f'Loading DeepER_best_model_{int(perc*100)}_{DATASET_NAME}.h5', end='', flush=True)\n",
    "        deeper_model = load_model(f'DeepER_best_model_{int(perc*100)}_{DATASET_NAME}.h5')\n",
    "        print('  ->  Done')        \n",
    "                \n",
    "    else:\n",
    "        \n",
    "        # Inizializza il modello.\n",
    "        deeper_model = init_DeepER_model(emb_dim)\n",
    "        deeper_model.summary()\n",
    "        # Avvio addestramento.\n",
    "        deeper_model = train_model_ER(sub_data, \n",
    "                                      deeper_model, \n",
    "                                      embeddings_model, \n",
    "                                      tokenizer, \n",
    "                                      pretraining=False, \n",
    "                                      end=f'_{int(perc*100)}_{DATASET_NAME}')\n",
    "        \n",
    "    return deeper_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avvio addestramenti o carica da disco.\n",
    "deeper_model_5 = get_DeepER(0.05)\n",
    "deeper_model_10 = get_DeepER(0.1)\n",
    "deeper_model_25 = get_DeepER(0.25)\n",
    "deeper_model_50 = get_DeepER(0.5)\n",
    "deeper_model_75 = get_DeepER(0.75)\n",
    "deeper_model_100 = get_DeepER(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcolo F-Measure dopo addestramento standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Misurazione dell'f-measure sullo stesso test set con i diversi modelli.\n",
    "fm_model_standard = [model_statistics(deeper_test, deeper_model_100, embeddings_model, tokenizer),\n",
    "                     model_statistics(deeper_test, deeper_model_75, embeddings_model, tokenizer),\n",
    "                     model_statistics(deeper_test, deeper_model_50, embeddings_model, tokenizer),\n",
    "                     model_statistics(deeper_test, deeper_model_25, embeddings_model, tokenizer),\n",
    "                     model_statistics(deeper_test, deeper_model_10, embeddings_model, tokenizer),\n",
    "                     model_statistics(deeper_test, deeper_model_5, embeddings_model, tokenizer)]\n",
    "\n",
    "print(fm_model_standard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizzazione F-Measure: primi risultati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Attiva modalità notebook per mostrare i grafici correttamente.\n",
    "pyo.init_notebook_mode()\n",
    "\n",
    "splits = ['100% split', '75% split', '50% split', '25% split', '10% split', '5% split']\n",
    "total_tup = len(deeper_train)\n",
    "tuplecount = [total_tup, \n",
    "              int(total_tup*0.75), \n",
    "              int(total_tup*0.5), \n",
    "              int(total_tup*0.25), \n",
    "              int(total_tup*0.1), \n",
    "              int(total_tup*0.05)]\n",
    "\n",
    "# Aggiungi descrizione al numero\n",
    "tuplecount = list(map(lambda x: f'{x} coppie di tuple', tuplecount))\n",
    "\n",
    "fig = go.Figure(data=[go.Bar(name='DeepER', x=splits, y=fm_model_standard, hovertext=tuplecount)])\n",
    "\n",
    "#fig.show()\n",
    "\n",
    "# Plotta il grafico e salvalo come features_standard.html (verrà integrato nell'html).\n",
    "pyo.iplot(fig, filename='fmeasures-standard')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Al passaggio del mouse il grafico mostra:\n",
    "- Il numero di coppie di tuple utilizzate per l'addestramento; \n",
    "- La percentuale di split (Quantità di tuple utilizzate per addestrare il modello);\n",
    "- Il valore di F-Measure (media armonica tra precision e recall);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Addestramento con Pre-Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Addestramento modello VinSim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Caricamento o addestramento del modello per la similarità.\n",
    "if LOAD_FROM_DISK:    \n",
    "    \n",
    "    vinsim_model = load_model(f'VinSim_best_model_{DATASET_NAME}.h5')\n",
    "    \n",
    "else:\n",
    "    \n",
    "    # Dataset per VinSim.\n",
    "    vinsim_data = []\n",
    "    \n",
    "    # Porzione di tuple in match da includere nell'addestramento di VinSim.\n",
    "    TP_FACTOR = 0.2\n",
    "    \n",
    "    # Preleva solo quelle in match con il relativo sim vector.\n",
    "    for i in range(len(data)):\n",
    "        if data[i][3] == 1:\n",
    "            r = data[i]\n",
    "            vinsim_data.append((r[0], r[1], r[2]))\n",
    "            \n",
    "    # Taglio della porzione desiderata.\n",
    "    bound = int(len(vinsim_data) * TP_FACTOR)\n",
    "    vinsim_data = vinsim_data[:bound]\n",
    "    \n",
    "    # Generazione di tuple random.\n",
    "    random_tuples = csvTable2datasetRANDOM(TABLE1_FILE, TABLE2_FILE, len(data)*2, att_indexes, simf)\n",
    "    \n",
    "    # Concatenazione.\n",
    "    vinsim_data += random_tuples\n",
    "    \n",
    "    # Shuffle.\n",
    "    shuffle(vinsim_data)\n",
    "    \n",
    "    # Filtro.\n",
    "    vinsim_data = shrink_data(vinsim_data)\n",
    "        \n",
    "    # Inizializza un nuovo modello.\n",
    "    vinsim_model = init_DeepER_model(emb_dim)\n",
    "\n",
    "    # Sostituisci ultimo layer e ricompila per l'addestramento.\n",
    "    output_neurons = len(vinsim_data[0][2]) # Parametrico rispetto alla dimensione del vettore di similarità.\n",
    "    vinsim_model = replace_last_layer(vinsim_model, Dense(output_neurons, activation='sigmoid', name='VinSim'))    \n",
    "    vinsim_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    vinsim_model.summary()\n",
    "\n",
    "    # Avvia l'addestramento. \n",
    "    train_model_ER(vinsim_data, \n",
    "                   vinsim_model, \n",
    "                   embeddings_model, \n",
    "                   tokenizer, \n",
    "                   pretraining=True, \n",
    "                   metric='val_loss', \n",
    "                   end=f'_{DATASET_NAME}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addestramento VinSim + DeepER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Input: Percentuale di dati considerata per l'addestramento.\n",
    "# Output: DeepER addestrato con preaddestramento VinSim.\n",
    "def get_PreTrained(perc):\n",
    "   \n",
    "    sub_data = splitting_dataSet(perc, deeper_train)       \n",
    "    \n",
    "    if LOAD_FROM_DISK:\n",
    "        \n",
    "        # Carica da disco.      \n",
    "        print(f'Loading DeepER_best_model_{int(perc*100)}_pre_{DATASET_NAME}.h5', end='', flush=True)\n",
    "        deeper_model_pre = load_model(f'DeepER_best_model_{int(perc*100)}_pre_{DATASET_NAME}.h5')\n",
    "        print('  ->  Done') \n",
    "        \n",
    "    else:\n",
    "        \n",
    "        # Utilizza il modello addestrato sulla similarità per l'addestramento (transfer learning).\n",
    "        deeper_model_pre = load_model(f'VinSim_best_model_{DATASET_NAME}.h5')\n",
    "        deeper_model_pre = replace_last_layer(deeper_model_pre, Dense(2, activation='softmax', name='Classification'))\n",
    "        deeper_model_pre.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        deeper_model_pre.summary()\n",
    "        deeper_model_pre = train_model_ER(sub_data, \n",
    "                                          deeper_model_pre, \n",
    "                                          embeddings_model, \n",
    "                                          tokenizer, \n",
    "                                          pretraining=False, \n",
    "                                          end=f'_{int(perc*100)}_pre_{DATASET_NAME}')     \n",
    "    \n",
    "    return deeper_model_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avvio addestramenti o carica da disco.\n",
    "deeper_model_5_pre = get_PreTrained(0.05)\n",
    "deeper_model_10_pre = get_PreTrained(0.1)\n",
    "deeper_model_25_pre = get_PreTrained(0.25)\n",
    "deeper_model_50_pre = get_PreTrained(0.5)\n",
    "deeper_model_75_pre = get_PreTrained(0.75)\n",
    "deeper_model_100_pre = get_PreTrained(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F-Measure per VinSim + DeepER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Misurazione dell'f-measure sullo stesso test set con i diversi modelli.\n",
    "fm_model_pre_trained = [model_statistics(deeper_test, deeper_model_100_pre, embeddings_model, tokenizer),\n",
    "                        model_statistics(deeper_test, deeper_model_75_pre, embeddings_model, tokenizer),\n",
    "                        model_statistics(deeper_test, deeper_model_50_pre, embeddings_model, tokenizer),\n",
    "                        model_statistics(deeper_test, deeper_model_25_pre, embeddings_model, tokenizer),\n",
    "                        model_statistics(deeper_test, deeper_model_10_pre, embeddings_model, tokenizer),\n",
    "                        model_statistics(deeper_test, deeper_model_5_pre, embeddings_model, tokenizer)]\n",
    "\n",
    "print(fm_model_pre_trained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizzazione F-Measure: comparazione finale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = go.Figure(data=[go.Bar(name='DeepER standard', x=splits, y=fm_model_standard),\n",
    "                       go.Bar(name='VinSim + DeepER', x=splits, y=fm_model_pre_trained)])\n",
    "\n",
    "# Modalità di visualizzazione con colonne raggruppate.\n",
    "fig2.update_layout(barmode='group')\n",
    "#fig.show()\n",
    "\n",
    "# Plotta il grafico e salvalo come features_comparison.html (verrà integrato nell'html).\n",
    "pyo.iplot(fig2, filename='fmeasures-comparison')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
