{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DeepER Classic "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Caricamento dati, preprocessing e strutture ausiliarie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from DeepER import init_embeddings_index, init_embeddings_model, init_DeepER_model, train_model_ER, replace_last_layer, model_statistics\n",
    "from experimental_similarity import mono_vector, cosine_similarity_vector, distance_similarity_vector\n",
    "from csv2dataset import splitting_dataSet, csv_2_datasetALTERNATE, csvTable2datasetRANDOM\n",
    "from generate_similarity_vector import generate_similarity_vector\n",
    "from data_reg import sim_hamming\n",
    "from keras.models import load_model\n",
    "from keras.layers import Dense\n",
    "from plotly import graph_objs as go\n",
    "import plotly.offline as pyo\n",
    "from random import shuffle\n",
    "import utilist as uls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imposta manualmente a True per caricare da disco tutti i modelli salvati. \n",
    "# Imposta manualmente a False per ri-eseguire tutti gli addestramenti.\n",
    "LOAD_FROM_DISK_DATASET=False\n",
    "LOAD_FROM_DISK_MODEL = False\n",
    "# Il nome con cui saranno etichettati i files prodotti\n",
    "DATASET_NAME = 'wa_Anhai'# Esempio: 'WA'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Costruzione indice degli embeddings.....Fatto. 400000 embeddings totali.\n",
      "* Creazione del modello per il calcolo degli embeddings....\n",
      "* Inizializzo il tokenizzatore.....Fatto: 400000 parole totali.\n",
      "* Preparazione della matrice di embedding.....Fatto. Dimensioni matrice embeddings: (400001, 50)\n",
      "\n",
      "°°° EMBEDDING MODEL °°°\n",
      "Model: \"model_1\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Tupla_A (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Tupla_B (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Embedding_lookup (Embedding)    (None, None, 50)     20000050    Tupla_A[0][0]                    \n",
      "                                                                 Tupla_B[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 20,000,050\n",
      "Trainable params: 0\n",
      "Non-trainable params: 20,000,050\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# Caricamento strutture dati e modelli ausiliari.\n",
    "embeddings_index = init_embeddings_index('glove.6B.50d.txt')\n",
    "emb_dim = len(embeddings_index['cat']) # :3\n",
    "embeddings_model, tokenizer = init_embeddings_model(embeddings_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "289\n",
      "577\n"
     ]
    }
   ],
   "source": [
    "# Caricamento dati e split iniziale.\n",
    "if LOAD_FROM_DISK_DATASET:\n",
    "    \n",
    "    # Carica dataset salvato su disco.\n",
    "    data = uls.load_list(f'dataset_{DATASET_NAME}')\n",
    "    match_number=sum(map(lambda x : x[3] == 1, data))\n",
    "    print(match_number)\n",
    "    print(len(data))\n",
    "\n",
    "else:\n",
    "    \n",
    "    GROUND_TRUTH_FILE = 'matches_fodors_zagats.csv'# Esempio: 'matches_walmart_amazon.csv'\n",
    "    # Necessario inserire le tabelle nell'ordine corrispondente alle coppie della ground truth.\n",
    "    TABLE1_FILE = 'fodors.csv'# Esempio: 'walmart.csv'\n",
    "    TABLE2_FILE = 'zagats.csv'# Esempio: 'amazon.csv'\n",
    "\n",
    "    # Coppie di attributi considerati allineati.\n",
    "    att_indexes = [(1, 1), (2, 2), (3, 3), (4, 4),(5, 5), (6, 6)]# Esempio: [(5, 9), (4, 5), (3, 3), (14, 4), (6, 11)]\n",
    "\n",
    "\n",
    "    # Similarity callbacks\n",
    "    #simf= lambda a,b: books_vector15(a,b)\n",
    "    #simf= lambda a,b: books_vector14(a,b)\n",
    "    simf= lambda a,b: sim_hamming(a,b)\n",
    "    #simf = lambda a, b: cosine_similarity_vector(a, b, embeddings_index)\n",
    "    #simf = lambda a, b: mono_vector(a, b)\n",
    "\n",
    "    # Crea il dataset.\n",
    "    data = csv_2_datasetALTERNATE(GROUND_TRUTH_FILE, TABLE1_FILE, TABLE2_FILE, att_indexes, simf)\n",
    "    \n",
    "    # Salva dataset su disco.\n",
    "    uls.save_list(data, f'dataset_{DATASET_NAME}')\n",
    "\n",
    "    \n",
    "# Dataset per DeepER classico: [(tupla1, tupla2, label), ...].\n",
    "deeper_data = list(map(lambda q: (q[0], q[1], q[3]), data))\n",
    "\n",
    "\n",
    "# Taglia attributi se troppo lunghi\n",
    "# Alcuni dataset hanno attributi con descrizioni molto lunghe.\n",
    "# Questo filtro limita il numero di caratteri di un attributo a 1000.\n",
    "def shrink_data(data):\n",
    "    \n",
    "    def cut_string(s):\n",
    "        if len(s) >= 1000:\n",
    "            return s[:1000]\n",
    "        else:\n",
    "            return s\n",
    "    \n",
    "    temp = []\n",
    "    for t1, t2, lb in data:\n",
    "        t1 = list(map(cut_string, t1))\n",
    "        t2 = list(map(cut_string, t2))\n",
    "        temp.append((t1, t2, lb))\n",
    "        \n",
    "    return temp\n",
    "\n",
    "deeper_data = shrink_data(deeper_data)\n",
    "\n",
    "\n",
    "# Split in training set e test set.\n",
    "def split_training_test(data, SPLIT_FACTOR = 0.8):     \n",
    "    bound = int(len(data) * SPLIT_FACTOR)\n",
    "    train = data[:bound]\n",
    "    test = data[bound:]\n",
    "    \n",
    "    return train, test\n",
    "\n",
    "\n",
    "# Tutti i successivi addestramenti partiranno dal 100% di deeper_train (80% di tutti i dati).\n",
    "# Le tuple in deeper_test non verranno mai usate per addestrare ma solo per testare i modelli.\n",
    "deeper_train, deeper_test = split_training_test(deeper_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 1: Addestramento standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# InPut: Percentuale di dati considerata per l'addestramento. \n",
    "# OutPut: DeepER addestrato sul taglio scelto.\n",
    "def get_DeepER(perc):\n",
    "   \n",
    "    sub_data = splitting_dataSet(perc, deeper_train)    \n",
    "    \n",
    "    if LOAD_FROM_DISK:\n",
    "        \n",
    "        # Carica da disco.\n",
    "        print(f'Loading DeepER_best_model_{int(perc*100)}_{DATASET_NAME}.h5', end='', flush=True)\n",
    "        deeper_model = load_model(f'DeepER_best_model_{int(perc*100)}_{DATASET_NAME}.h5')\n",
    "        print('  ->  Done')        \n",
    "                \n",
    "    else:\n",
    "        \n",
    "        # Inizializza il modello.\n",
    "        deeper_model = init_DeepER_model(emb_dim)\n",
    "        deeper_model.summary()\n",
    "        # Avvio addestramento.\n",
    "        deeper_model = train_model_ER(sub_data, \n",
    "                                      deeper_model, \n",
    "                                      embeddings_model, \n",
    "                                      tokenizer, \n",
    "                                      pretraining=False, \n",
    "                                      end=f'_{int(perc*100)}_{DATASET_NAME}')\n",
    "        \n",
    "    return deeper_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "°°° DeepER Model °°°\n",
      "Model: \"model_2\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Embeddings_seq_a (InputLayer)   (None, None, 50)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Embeddings_seq_b (InputLayer)   (None, None, 50)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Composition (Bidirectional)     (None, 300)          241200      Embeddings_seq_a[0][0]           \n",
      "                                                                 Embeddings_seq_b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Similarity (Lambda)             (None, 300)          0           Composition[0][0]                \n",
      "                                                                 Composition[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Dense1 (Dense)                  (None, 300)          90300       Similarity[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Dense2 (Dense)                  (None, 300)          90300       Dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Classification (Dense)          (None, 2)            602         Dense2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 422,402\n",
      "Trainable params: 422,402\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "* Preparazione input......Fatto. 23 tuple totali, esempio label: 1 -> [0. 1.], Table1 shape: (23, 26), Table2 shape: (23, 23)\n",
      "Batch size: 1\n",
      "Train on 18 samples, validate on 5 samples\n",
      "Epoch 1/64\n",
      "18/18 [==============================] - 2s 131ms/step - loss: 0.6966 - accuracy: 0.4444 - val_loss: 0.6740 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.80000, saving model to DeepER_best_model_5_wa_Anhai.h5\n",
      "Epoch 2/64\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.6992 - accuracy: 0.6111 - val_loss: 0.6655 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.80000\n",
      "Epoch 3/64\n",
      "18/18 [==============================] - 1s 38ms/step - loss: 0.5566 - accuracy: 0.8889 - val_loss: 0.6037 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.80000\n",
      "Epoch 4/64\n",
      "18/18 [==============================] - 1s 41ms/step - loss: 0.2959 - accuracy: 0.8889 - val_loss: 0.8222 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.80000\n",
      "Epoch 5/64\n",
      "18/18 [==============================] - 1s 36ms/step - loss: 0.1545 - accuracy: 0.8889 - val_loss: 1.1388 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.80000\n",
      "Epoch 6/64\n",
      "18/18 [==============================] - 1s 44ms/step - loss: 0.1593 - accuracy: 0.9444 - val_loss: 0.7352 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.80000\n",
      "Epoch 7/64\n",
      "18/18 [==============================] - 1s 45ms/step - loss: 0.0075 - accuracy: 1.0000 - val_loss: 1.1029 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.80000\n",
      "Epoch 8/64\n",
      "18/18 [==============================] - 1s 42ms/step - loss: 8.9921e-04 - accuracy: 1.0000 - val_loss: 1.0929 - val_accuracy: 0.8000\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.80000\n",
      "Epoch 00008: early stopping\n",
      "\n",
      "°°° DeepER Model °°°\n",
      "Model: \"model_3\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Embeddings_seq_a (InputLayer)   (None, None, 50)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Embeddings_seq_b (InputLayer)   (None, None, 50)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Composition (Bidirectional)     (None, 300)          241200      Embeddings_seq_a[0][0]           \n",
      "                                                                 Embeddings_seq_b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Similarity (Lambda)             (None, 300)          0           Composition[0][0]                \n",
      "                                                                 Composition[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Dense1 (Dense)                  (None, 300)          90300       Similarity[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Dense2 (Dense)                  (None, 300)          90300       Dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Classification (Dense)          (None, 2)            602         Dense2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 422,402\n",
      "Trainable params: 422,402\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "* Preparazione input......Fatto. 46 tuple totali, esempio label: 1 -> [0. 1.], Table1 shape: (46, 26), Table2 shape: (46, 23)\n",
      "Batch size: 2\n",
      "Train on 36 samples, validate on 10 samples\n",
      "Epoch 1/64\n",
      "36/36 [==============================] - 2s 66ms/step - loss: 0.6933 - accuracy: 0.5000 - val_loss: 0.6949 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.60000, saving model to DeepER_best_model_10_wa_Anhai.h5\n",
      "Epoch 2/64\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.6252 - accuracy: 0.8056 - val_loss: 0.7630 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.60000\n",
      "Epoch 3/64\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 0.4082 - accuracy: 0.9167 - val_loss: 1.2775 - val_accuracy: 0.6000\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.60000\n",
      "Epoch 4/64\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.4038 - accuracy: 0.7500 - val_loss: 0.7278 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00004: val_accuracy did not improve from 0.60000\n",
      "Epoch 5/64\n",
      "36/36 [==============================] - 1s 25ms/step - loss: 0.2384 - accuracy: 0.8889 - val_loss: 1.0393 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.60000\n",
      "Epoch 6/64\n",
      "36/36 [==============================] - 1s 24ms/step - loss: 0.1024 - accuracy: 0.9722 - val_loss: 3.0107 - val_accuracy: 0.3000\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.60000\n",
      "Epoch 7/64\n",
      "36/36 [==============================] - 1s 23ms/step - loss: 0.3840 - accuracy: 0.9444 - val_loss: 1.4755 - val_accuracy: 0.5000\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.60000\n",
      "Epoch 8/64\n",
      "36/36 [==============================] - 1s 26ms/step - loss: 0.1809 - accuracy: 0.9722 - val_loss: 0.8714 - val_accuracy: 0.4000\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.60000\n",
      "Epoch 00008: early stopping\n",
      "\n",
      "°°° DeepER Model °°°\n",
      "Model: \"model_4\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Embeddings_seq_a (InputLayer)   (None, None, 50)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Embeddings_seq_b (InputLayer)   (None, None, 50)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Composition (Bidirectional)     (None, 300)          241200      Embeddings_seq_a[0][0]           \n",
      "                                                                 Embeddings_seq_b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Similarity (Lambda)             (None, 300)          0           Composition[0][0]                \n",
      "                                                                 Composition[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Dense1 (Dense)                  (None, 300)          90300       Similarity[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Dense2 (Dense)                  (None, 300)          90300       Dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Classification (Dense)          (None, 2)            602         Dense2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 422,402\n",
      "Trainable params: 422,402\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Preparazione input......Fatto. 115 tuple totali, esempio label: 1 -> [0. 1.], Table1 shape: (115, 27), Table2 shape: (115, 27)\n",
      "Batch size: 3\n",
      "Train on 92 samples, validate on 23 samples\n",
      "Epoch 1/64\n",
      "92/92 [==============================] - 4s 46ms/step - loss: 0.6994 - accuracy: 0.4348 - val_loss: 0.6805 - val_accuracy: 0.6957\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.69565, saving model to DeepER_best_model_25_wa_Anhai.h5\n",
      "Epoch 2/64\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.6714 - accuracy: 0.6413 - val_loss: 0.6381 - val_accuracy: 0.6087\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.69565\n",
      "Epoch 3/64\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.5548 - accuracy: 0.7391 - val_loss: 0.5551 - val_accuracy: 0.7826\n",
      "\n",
      "Epoch 00003: val_accuracy improved from 0.69565 to 0.78261, saving model to DeepER_best_model_25_wa_Anhai.h5\n",
      "Epoch 4/64\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.4047 - accuracy: 0.8587 - val_loss: 0.5488 - val_accuracy: 0.8261\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.78261 to 0.82609, saving model to DeepER_best_model_25_wa_Anhai.h5\n",
      "Epoch 5/64\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.2386 - accuracy: 0.8804 - val_loss: 0.6261 - val_accuracy: 0.7826\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.82609\n",
      "Epoch 6/64\n",
      "92/92 [==============================] - 2s 18ms/step - loss: 0.1549 - accuracy: 0.9565 - val_loss: 0.6377 - val_accuracy: 0.7391\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.82609\n",
      "Epoch 7/64\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.1666 - accuracy: 0.9239 - val_loss: 0.5246 - val_accuracy: 0.7391\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.82609\n",
      "Epoch 8/64\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0782 - accuracy: 0.9783 - val_loss: 0.7483 - val_accuracy: 0.7826\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.82609\n",
      "Epoch 9/64\n",
      "92/92 [==============================] - 2s 16ms/step - loss: 0.0689 - accuracy: 0.9674 - val_loss: 0.8104 - val_accuracy: 0.7391\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.82609\n",
      "Epoch 10/64\n",
      "92/92 [==============================] - 2s 17ms/step - loss: 0.0435 - accuracy: 0.9891 - val_loss: 0.8127 - val_accuracy: 0.7391\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.82609\n",
      "Epoch 11/64\n",
      "92/92 [==============================] - 1s 16ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 0.9478 - val_accuracy: 0.6957\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.82609\n",
      "Epoch 00011: early stopping\n",
      "\n",
      "°°° DeepER Model °°°\n",
      "Model: \"model_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Embeddings_seq_a (InputLayer)   (None, None, 50)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Embeddings_seq_b (InputLayer)   (None, None, 50)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Composition (Bidirectional)     (None, 300)          241200      Embeddings_seq_a[0][0]           \n",
      "                                                                 Embeddings_seq_b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Similarity (Lambda)             (None, 300)          0           Composition[0][0]                \n",
      "                                                                 Composition[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Dense1 (Dense)                  (None, 300)          90300       Similarity[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Dense2 (Dense)                  (None, 300)          90300       Dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Classification (Dense)          (None, 2)            602         Dense2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 422,402\n",
      "Trainable params: 422,402\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "* Preparazione input......Fatto. 230 tuple totali, esempio label: 1 -> [0. 1.], Table1 shape: (230, 27), Table2 shape: (230, 29)\n",
      "Batch size: 4\n",
      "Train on 184 samples, validate on 46 samples\n",
      "Epoch 1/64\n",
      "184/184 [==============================] - 4s 24ms/step - loss: 0.6902 - accuracy: 0.5435 - val_loss: 0.7005 - val_accuracy: 0.5435\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.54348, saving model to DeepER_best_model_50_wa_Anhai.h5\n",
      "Epoch 2/64\n",
      "184/184 [==============================] - 2s 13ms/step - loss: 0.6193 - accuracy: 0.6685 - val_loss: 0.7426 - val_accuracy: 0.5435\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.54348\n",
      "Epoch 3/64\n",
      "184/184 [==============================] - 2s 13ms/step - loss: 0.4745 - accuracy: 0.8098 - val_loss: 0.9589 - val_accuracy: 0.5217\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.54348\n",
      "Epoch 4/64\n",
      "184/184 [==============================] - 2s 13ms/step - loss: 0.4011 - accuracy: 0.8315 - val_loss: 0.7829 - val_accuracy: 0.6522\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.54348 to 0.65217, saving model to DeepER_best_model_50_wa_Anhai.h5\n",
      "Epoch 5/64\n",
      "184/184 [==============================] - 2s 13ms/step - loss: 0.3071 - accuracy: 0.8641 - val_loss: 0.9965 - val_accuracy: 0.6304\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.65217\n",
      "Epoch 6/64\n",
      "184/184 [==============================] - 2s 13ms/step - loss: 0.1819 - accuracy: 0.9348 - val_loss: 1.0056 - val_accuracy: 0.6087\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.65217\n",
      "Epoch 7/64\n",
      "184/184 [==============================] - 2s 13ms/step - loss: 0.1021 - accuracy: 0.9674 - val_loss: 1.0401 - val_accuracy: 0.6087\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.65217\n",
      "Epoch 8/64\n",
      "184/184 [==============================] - 2s 13ms/step - loss: 0.0340 - accuracy: 0.9891 - val_loss: 1.4650 - val_accuracy: 0.6087\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.65217\n",
      "Epoch 9/64\n",
      "184/184 [==============================] - 2s 13ms/step - loss: 0.0861 - accuracy: 0.9728 - val_loss: 2.0435 - val_accuracy: 0.5870\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.65217\n",
      "Epoch 10/64\n",
      "184/184 [==============================] - 2s 14ms/step - loss: 0.0940 - accuracy: 0.9728 - val_loss: 1.2958 - val_accuracy: 0.5435\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.65217\n",
      "Epoch 11/64\n",
      "184/184 [==============================] - 2s 13ms/step - loss: 0.0167 - accuracy: 1.0000 - val_loss: 1.5079 - val_accuracy: 0.6087\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.65217\n",
      "Epoch 00011: early stopping\n",
      "\n",
      "°°° DeepER Model °°°\n",
      "Model: \"model_6\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Embeddings_seq_a (InputLayer)   (None, None, 50)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Embeddings_seq_b (InputLayer)   (None, None, 50)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Composition (Bidirectional)     (None, 300)          241200      Embeddings_seq_a[0][0]           \n",
      "                                                                 Embeddings_seq_b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Similarity (Lambda)             (None, 300)          0           Composition[0][0]                \n",
      "                                                                 Composition[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Dense1 (Dense)                  (None, 300)          90300       Similarity[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Dense2 (Dense)                  (None, 300)          90300       Dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Classification (Dense)          (None, 2)            602         Dense2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 422,402\n",
      "Trainable params: 422,402\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "* Preparazione input......Fatto. 345 tuple totali, esempio label: 1 -> [0. 1.], Table1 shape: (345, 27), Table2 shape: (345, 29)\n",
      "Batch size: 6\n",
      "Train on 276 samples, validate on 69 samples\n",
      "Epoch 1/64\n",
      "276/276 [==============================] - 4s 14ms/step - loss: 0.6834 - accuracy: 0.5399 - val_loss: 0.6247 - val_accuracy: 0.7391\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.73913, saving model to DeepER_best_model_75_wa_Anhai.h5\n",
      "Epoch 2/64\n",
      "276/276 [==============================] - 2s 9ms/step - loss: 0.5832 - accuracy: 0.6957 - val_loss: 0.5543 - val_accuracy: 0.7391\n",
      "\n",
      "Epoch 00002: val_accuracy did not improve from 0.73913\n",
      "Epoch 3/64\n",
      "276/276 [==============================] - 3s 10ms/step - loss: 0.4313 - accuracy: 0.8116 - val_loss: 0.5246 - val_accuracy: 0.6812\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.73913\n",
      "Epoch 4/64\n",
      "276/276 [==============================] - 4s 14ms/step - loss: 0.2670 - accuracy: 0.9022 - val_loss: 0.5512 - val_accuracy: 0.7971\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.73913 to 0.79710, saving model to DeepER_best_model_75_wa_Anhai.h5\n",
      "Epoch 5/64\n",
      "276/276 [==============================] - 3s 10ms/step - loss: 0.1807 - accuracy: 0.9420 - val_loss: 0.6412 - val_accuracy: 0.6812\n",
      "\n",
      "Epoch 00005: val_accuracy did not improve from 0.79710\n",
      "Epoch 6/64\n",
      "276/276 [==============================] - 2s 9ms/step - loss: 0.1431 - accuracy: 0.9348 - val_loss: 0.7494 - val_accuracy: 0.7681\n",
      "\n",
      "Epoch 00006: val_accuracy did not improve from 0.79710\n",
      "Epoch 7/64\n",
      "276/276 [==============================] - 3s 10ms/step - loss: 0.1029 - accuracy: 0.9746 - val_loss: 0.7616 - val_accuracy: 0.7971\n",
      "\n",
      "Epoch 00007: val_accuracy did not improve from 0.79710\n",
      "Epoch 8/64\n",
      "276/276 [==============================] - 3s 9ms/step - loss: 0.1299 - accuracy: 0.9565 - val_loss: 0.8989 - val_accuracy: 0.7101\n",
      "\n",
      "Epoch 00008: val_accuracy did not improve from 0.79710\n",
      "Epoch 9/64\n",
      "276/276 [==============================] - 2s 9ms/step - loss: 0.0604 - accuracy: 0.9710 - val_loss: 0.7358 - val_accuracy: 0.7391\n",
      "\n",
      "Epoch 00009: val_accuracy did not improve from 0.79710\n",
      "Epoch 10/64\n",
      "276/276 [==============================] - 3s 9ms/step - loss: 0.0517 - accuracy: 0.9783 - val_loss: 1.0492 - val_accuracy: 0.7101\n",
      "\n",
      "Epoch 00010: val_accuracy did not improve from 0.79710\n",
      "Epoch 11/64\n",
      "276/276 [==============================] - 3s 9ms/step - loss: 0.0381 - accuracy: 0.9855 - val_loss: 0.9419 - val_accuracy: 0.7536\n",
      "\n",
      "Epoch 00011: val_accuracy did not improve from 0.79710\n",
      "Epoch 00011: early stopping\n",
      "\n",
      "°°° DeepER Model °°°\n",
      "Model: \"model_7\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "Embeddings_seq_a (InputLayer)   (None, None, 50)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Embeddings_seq_b (InputLayer)   (None, None, 50)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Composition (Bidirectional)     (None, 300)          241200      Embeddings_seq_a[0][0]           \n",
      "                                                                 Embeddings_seq_b[0][0]           \n",
      "__________________________________________________________________________________________________\n",
      "Similarity (Lambda)             (None, 300)          0           Composition[0][0]                \n",
      "                                                                 Composition[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "Dense1 (Dense)                  (None, 300)          90300       Similarity[0][0]                 \n",
      "__________________________________________________________________________________________________\n",
      "Dense2 (Dense)                  (None, 300)          90300       Dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "Classification (Dense)          (None, 2)            602         Dense2[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 422,402\n",
      "Trainable params: 422,402\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "* Preparazione input......Fatto. 461 tuple totali, esempio label: 1 -> [0. 1.], Table1 shape: (461, 27), Table2 shape: (461, 37)\n",
      "Batch size: 8\n",
      "Train on 368 samples, validate on 93 samples\n",
      "Epoch 1/64\n",
      "368/368 [==============================] - 7s 20ms/step - loss: 0.6853 - accuracy: 0.5571 - val_loss: 0.6666 - val_accuracy: 0.5806\n",
      "\n",
      "Epoch 00001: val_accuracy improved from -inf to 0.58065, saving model to DeepER_best_model_100_wa_Anhai.h5\n",
      "Epoch 2/64\n",
      "368/368 [==============================] - 4s 10ms/step - loss: 0.5826 - accuracy: 0.6957 - val_loss: 0.5988 - val_accuracy: 0.7204\n",
      "\n",
      "Epoch 00002: val_accuracy improved from 0.58065 to 0.72043, saving model to DeepER_best_model_100_wa_Anhai.h5\n",
      "Epoch 3/64\n",
      "368/368 [==============================] - 5s 13ms/step - loss: 0.4622 - accuracy: 0.8043 - val_loss: 0.6534 - val_accuracy: 0.6774\n",
      "\n",
      "Epoch 00003: val_accuracy did not improve from 0.72043\n",
      "Epoch 4/64\n",
      "368/368 [==============================] - 5s 12ms/step - loss: 0.3576 - accuracy: 0.8478 - val_loss: 0.5154 - val_accuracy: 0.7527\n",
      "\n",
      "Epoch 00004: val_accuracy improved from 0.72043 to 0.75269, saving model to DeepER_best_model_100_wa_Anhai.h5\n",
      "Epoch 5/64\n",
      "352/368 [===========================>..] - ETA: 0s - loss: 0.2527 - accuracy: 0.9034"
     ]
    }
   ],
   "source": [
    "# Avvio addestramenti o carica da disco.\n",
    "deeper_model_5 = get_DeepER(0.05)\n",
    "deeper_model_10 = get_DeepER(0.1)\n",
    "deeper_model_25 = get_DeepER(0.25)\n",
    "deeper_model_50 = get_DeepER(0.5)\n",
    "deeper_model_75 = get_DeepER(0.75)\n",
    "deeper_model_100 = get_DeepER(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcolo F-Measure dopo addestramento standard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Misurazione dell'f-measure sullo stesso test set con i diversi modelli.\n",
    "fm_model_standard = [model_statistics(deeper_test, deeper_model_100, embeddings_model, tokenizer),\n",
    "                     model_statistics(deeper_test, deeper_model_75, embeddings_model, tokenizer),\n",
    "                     model_statistics(deeper_test, deeper_model_50, embeddings_model, tokenizer),\n",
    "                     model_statistics(deeper_test, deeper_model_25, embeddings_model, tokenizer),\n",
    "                     model_statistics(deeper_test, deeper_model_10, embeddings_model, tokenizer),\n",
    "                     model_statistics(deeper_test, deeper_model_5, embeddings_model, tokenizer)]\n",
    "\n",
    "print(fm_model_standard)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizzazione F-Measure: primi risultati"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Attiva modalità notebook per mostrare i grafici correttamente.\n",
    "pyo.init_notebook_mode()\n",
    "\n",
    "splits = ['100% split', '75% split', '50% split', '25% split', '10% split', '5% split']\n",
    "total_tup = len(deeper_train)\n",
    "tuplecount = [total_tup, \n",
    "              int(total_tup*0.75), \n",
    "              int(total_tup*0.5), \n",
    "              int(total_tup*0.25), \n",
    "              int(total_tup*0.1), \n",
    "              int(total_tup*0.05)]\n",
    "\n",
    "# Aggiungi descrizione al numero\n",
    "tuplecount = list(map(lambda x: f'{x} coppie di tuple', tuplecount))\n",
    "\n",
    "fig = go.Figure(data=[go.Bar(name='DeepER', x=splits, y=fm_model_standard, hovertext=tuplecount)])\n",
    "\n",
    "#fig.show()\n",
    "\n",
    "# Plotta il grafico e salvalo come features_standard.html (verrà integrato nell'html).\n",
    "pyo.iplot(fig, filename='fmeasures-standard')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Al passaggio del mouse il grafico mostra:\n",
    "- Il numero di coppie di tuple utilizzate per l'addestramento; \n",
    "- La percentuale di split (Quantità di tuple utilizzate per addestrare il modello);\n",
    "- Il valore di F-Measure (media armonica tra precision e recall);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 2: Addestramento con Pre-Train"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pre-Addestramento modello VinSim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Caricamento o addestramento del modello per la similarità.\n",
    "if LOAD_FROM_DISK:    \n",
    "    \n",
    "    vinsim_model = load_model(f'VinSim_best_model_{DATASET_NAME}.h5')\n",
    "    \n",
    "else:\n",
    "    \n",
    "    # Dataset per VinSim.\n",
    "    vinsim_data = []\n",
    "    \n",
    "    # Porzione di tuple in match da includere nell'addestramento di VinSim.\n",
    "    TP_FACTOR = 0.05\n",
    "    \n",
    "    # Preleva solo quelle in match con il relativo sim vector.\n",
    "    for i in range(len(data)):\n",
    "        if data[i][3] == 1:\n",
    "            r = data[i]\n",
    "            vinsim_data.append((r[0], r[1], r[2]))\n",
    "            \n",
    "    # Taglio della porzione desiderata.\n",
    "    bound = int(len(vinsim_data) * TP_FACTOR)\n",
    "    vinsim_data = vinsim_data[:bound]\n",
    "    \n",
    "    # Generazione di tuple random.\n",
    "    random_tuples = csvTable2datasetRANDOM(TABLE1_FILE, TABLE2_FILE, len(data)*2, att_indexes, simf)\n",
    "    \n",
    "    # Concatenazione.\n",
    "    vinsim_data += random_tuples\n",
    "    \n",
    "    # Shuffle.\n",
    "    shuffle(vinsim_data)\n",
    "    \n",
    "    # Filtro.\n",
    "    vinsim_data = shrink_data(vinsim_data)\n",
    "        \n",
    "    # Inizializza un nuovo modello.\n",
    "    vinsim_model = init_DeepER_model(emb_dim)\n",
    "\n",
    "    # Sostituisci ultimo layer e ricompila per l'addestramento.\n",
    "    output_neurons = len(vinsim_data[0][2]) # Parametrico rispetto alla dimensione del vettore di similarità.\n",
    "    vinsim_model = replace_last_layer(vinsim_model, Dense(output_neurons, activation='sigmoid', name='VinSim'))    \n",
    "    vinsim_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "    vinsim_model.summary()\n",
    "\n",
    "    # Avvia l'addestramento. \n",
    "    train_model_ER(vinsim_data, \n",
    "                   vinsim_model, \n",
    "                   embeddings_model, \n",
    "                   tokenizer, \n",
    "                   pretraining=True, \n",
    "                   metric='val_loss', \n",
    "                   end=f'_{DATASET_NAME}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Addestramento VinSim + DeepER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Input: Percentuale di dati considerata per l'addestramento.\n",
    "# Output: DeepER addestrato con preaddestramento VinSim.\n",
    "def get_PreTrained(perc):\n",
    "   \n",
    "    sub_data = splitting_dataSet(perc, deeper_train)       \n",
    "    \n",
    "    if LOAD_FROM_DISK:\n",
    "        \n",
    "        # Carica da disco.      \n",
    "        print(f'Loading DeepER_best_model_{int(perc*100)}_pre_{DATASET_NAME}.h5', end='', flush=True)\n",
    "        deeper_model_pre = load_model(f'DeepER_best_model_{int(perc*100)}_pre_{DATASET_NAME}.h5')\n",
    "        print('  ->  Done') \n",
    "        \n",
    "    else:\n",
    "        \n",
    "        # Utilizza il modello addestrato sulla similarità per l'addestramento (transfer learning).\n",
    "        deeper_model_pre = load_model(f'VinSim_best_model_{DATASET_NAME}.h5')\n",
    "        deeper_model_pre = replace_last_layer(deeper_model_pre, Dense(2, activation='softmax', name='Classification'))\n",
    "        deeper_model_pre.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "        deeper_model_pre.summary()\n",
    "        deeper_model_pre = train_model_ER(sub_data, \n",
    "                                          deeper_model_pre, \n",
    "                                          embeddings_model, \n",
    "                                          tokenizer, \n",
    "                                          pretraining=False, \n",
    "                                          end=f'_{int(perc*100)}_pre_{DATASET_NAME}')     \n",
    "    \n",
    "    return deeper_model_pre"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avvio addestramenti o carica da disco.\n",
    "deeper_model_5_pre = get_PreTrained(0.05)\n",
    "deeper_model_10_pre = get_PreTrained(0.1)\n",
    "deeper_model_25_pre = get_PreTrained(0.25)\n",
    "deeper_model_50_pre = get_PreTrained(0.5)\n",
    "deeper_model_75_pre = get_PreTrained(0.75)\n",
    "deeper_model_100_pre = get_PreTrained(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### F-Measure per VinSim + DeepER"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Misurazione dell'f-measure sullo stesso test set con i diversi modelli.\n",
    "fm_model_pre_trained = [model_statistics(deeper_test, deeper_model_100_pre, embeddings_model, tokenizer),\n",
    "                        model_statistics(deeper_test, deeper_model_75_pre, embeddings_model, tokenizer),\n",
    "                        model_statistics(deeper_test, deeper_model_50_pre, embeddings_model, tokenizer),\n",
    "                        model_statistics(deeper_test, deeper_model_25_pre, embeddings_model, tokenizer),\n",
    "                        model_statistics(deeper_test, deeper_model_10_pre, embeddings_model, tokenizer),\n",
    "                        model_statistics(deeper_test, deeper_model_5_pre, embeddings_model, tokenizer)]\n",
    "\n",
    "print(fm_model_pre_trained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualizzazione F-Measure: comparazione finale"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig2 = go.Figure(data=[go.Bar(name='DeepER standard', x=splits, y=fm_model_standard),\n",
    "                       go.Bar(name='VinSim + DeepER', x=splits, y=fm_model_pre_trained)])\n",
    "\n",
    "# Modalità di visualizzazione con colonne raggruppate.\n",
    "fig2.update_layout(barmode='group')\n",
    "#fig.show()\n",
    "\n",
    "# Plotta il grafico e salvalo come features_comparison.html (verrà integrato nell'html).\n",
    "pyo.iplot(fig2, filename='fmeasures-comparison')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
